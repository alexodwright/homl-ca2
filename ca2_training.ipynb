{"cells":[{"cell_type":"markdown","metadata":{"id":"nXMO8duG1z-5"},"source":["# Hands-On- Machine Learning CA2: Alex Wright"]},{"cell_type":"markdown","metadata":{"id":"lmua82f62BPj"},"source":["This continuous assessment aims to create an image classifier for `cars` and `boats`. This model aims to use the Python library `keras` to create and train neural networks to classify images on whether they are an image of a car or a boat. I will also implement transfer learning using neural networks that have already been pre-trained on the [ImageNet Dataset](https://www.image-net.org/), to ultimately create a model with the highest possible classification accuracy. The images I am using to train the network on cars was obtained from [Kaggle](https://www.kaggle.com), and can be found [here](https://www.kaggle.com/datasets/kshitij192/cars-image-dataset). The images used to train the model on boats was also obtained from Kaggle and can be found [here](https://www.kaggle.com/datasets/clorichel/boat-types-recognition)"]},{"cell_type":"markdown","metadata":{"id":"snxY6bsD39BR"},"source":["## Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HMf3wISx2AMd"},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","\n","from sklearn.model_selection import train_test_split\n","\n","from keras import Model\n","from keras import Input\n","from keras.layers import Dense\n","from keras.layers import Rescaling\n","from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import Flatten\n","from keras.layers import BatchNormalization\n","from keras.layers import Dropout\n","from keras.layers import RandomFlip\n","from keras.layers import RandomRotation\n","from keras.layers import RandomZoom\n","from keras.layers import RandomTranslation\n","\n","from keras.optimizers import RMSprop\n","\n","from keras.callbacks import EarlyStopping\n","\n","from keras.applications import ResNet50\n","\n","import keras.applications.resnet as resnet\n","\n","from keras.preprocessing.image import load_img\n","from keras.preprocessing import image_dataset_from_directory"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IcnV206a4HCf"},"outputs":[],"source":["# Since we are running this notebook on Google Colab\n","! pip install keras_tuner\n","\n","import keras_tuner"]},{"cell_type":"markdown","metadata":{"id":"-DWj6zzAmTw_"},"source":["## Setting the Random Seed"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KCp9JYDsmTAy"},"outputs":[],"source":["SEED = 2\n","tf.random.set_seed(SEED)\n","np.random.seed(SEED)"]},{"cell_type":"markdown","metadata":{"id":"opDNiFl74eP0"},"source":["## Reading in the images dataset from Google Drive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lTffhAgc4WPR"},"outputs":[],"source":["if 'google.colab' in str(get_ipython()):\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    base_dir = \"./drive/My Drive/homl-ca2\"\n","else:\n","    base_dir = \".\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nkdnfYCN62oB"},"outputs":[],"source":["train_dir = os.path.join(base_dir, \"train\")\n","test_dir = os.path.join(base_dir, \"test\")\n","val_dir = os.path.join(base_dir, \"val\")"]},{"cell_type":"markdown","metadata":{"id":"aihqQ6h99HNW"},"source":["Here we are reading in the image datasets from the appropriate directories, notice that the `label_mode` is set to `binary`, since we have only 2 classes, this is an example of binary classification."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KMoVWqo15jax"},"outputs":[],"source":["train_dataset = image_dataset_from_directory(directory=train_dir, label_mode=\"binary\", image_size=(224, 224))\n","test_dataset = image_dataset_from_directory(directory=test_dir, label_mode=\"binary\", image_size=(224, 224),)\n","val_dataset = image_dataset_from_directory(directory=val_dir, label_mode=\"binary\", image_size=(224, 224))"]},{"cell_type":"markdown","metadata":{"id":"bijEJzpO7YOC"},"source":["## Looking at examples of the classes of image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R3g6JtSu7avL"},"outputs":[],"source":["for image_class in os.listdir(train_dir):\n","  path = os.path.join(train_dir, image_class)\n","  image_path = os.path.join(path, os.listdir(path)[99])\n","  img = load_img(image_path)\n","  plt.imshow(img)\n","  plt.show()"]},{"cell_type":"markdown","metadata":{"id":"688UH3D28_F8"},"source":["Above, we can see an example of each of the class of image we will be training the neural networks to classify."]},{"cell_type":"markdown","metadata":{"id":"B8Ua2tdL_795"},"source":["## Function Definitions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F83UdMpt_7dm"},"outputs":[],"source":["def plot_keras_history(history, metric):\n","    fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n","    fig.tight_layout()\n","    axes[0].plot(history.history[\"loss\"], label=\"train loss\")\n","    axes[0].plot(history.history[\"val_loss\"], label=\"val loss\")\n","    axes[0].set_title(\"Loss\")\n","    axes[0].legend()\n","    axes[1].plot(history.history[metric], label=\"train \" + metric)\n","    axes[1].plot(history.history[\"val_\" + metric], label=\"val \" + metric)\n","    axes[1].set_title(metric)\n","    axes[1].legend()\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Vfrg_3xl-zKe"},"source":["## Model Selection"]},{"cell_type":"markdown","metadata":{"id":"h3M2c430AEC8"},"source":["First, we will experiement with an extremely simple model. This model will have no convolutional layers. It will contain an input layer, a rescaling layer, a single hidden layer with 512 units with ReLU as the activation function, and a dense output layer with one neuron (since this is a binary classification problem) using the sigmoid activation function.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U_WoeeAGCVWS"},"outputs":[],"source":["inputs = Input(shape=(224, 224, 3))\n","x = Rescaling(scale=1./255)(inputs)\n","x = Dense(units=512, activation=\"relu\")(x)\n","x = Flatten()(x)\n","outputs = Dense(units=1, activation=\"sigmoid\")(x)\n","simple_model = Model(inputs=inputs, outputs=outputs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y2XFkG8xEV2G"},"outputs":[],"source":["simple_model.compile(optimizer=RMSprop(learning_rate=0.001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9hxTtNKqEh07"},"outputs":[],"source":["simple_model_history = simple_model.fit(train_dataset, epochs=30, validation_data=val_dataset, callbacks=[EarlyStopping(monitor=\"val_loss\", patience=4, restore_best_weights=True)], verbose=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QIm4NB4kEyXj"},"outputs":[],"source":["train_acc, val_acc = simple_model_history.history[\"accuracy\"][-1], simple_model_history.history[\"val_accuracy\"][-1]\n","train_acc, val_acc"]},{"cell_type":"markdown","metadata":{"id":"KlNRf1agF68l"},"source":["As we can see from above, the model is very overfitting with the training accuracy being 100% and the validation accuracy being around 86%. This is because the model is 'memorizing' the training set as we are just passing it the raw pixels. We have not added any convolutional layers to allow our model to recognize features such as edges or shapes. We are also losing all spacial awareness by flattening the image without any convolutional layers. Since this model was expected to overfit, I am not going to try any further with this 'no convolutional layer' approach. (i.e. attempt to perform any regularization techniques, or reducing the complexity of the model)"]},{"cell_type":"markdown","metadata":{"id":"_MDu3jPoGf_O"},"source":["Let's plot the history to see how the accuracy improved (or declined) throughout the training phase."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zsJyk_KUFyQ-"},"outputs":[],"source":["plot_keras_history(simple_model_history, \"accuracy\")"]},{"cell_type":"markdown","metadata":{"id":"2GLwZJW6o5u6"},"source":["Let's have a look at the number of parameters of this simple model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"emt82LKaGrZk"},"outputs":[],"source":["simple_model.summary()"]},{"cell_type":"markdown","metadata":{"id":"4JZAsKEK8aFT"},"source":["We can see that this model has an extremely high number of parameters, with a whopping 51.4 million! This clearly explains why we have this significant level of overfitting. Let's see how much better we can get with a convolutional layered approach."]},{"cell_type":"markdown","metadata":{"id":"3du6T3GptglD"},"source":["### Convolutional Network"]},{"cell_type":"markdown","metadata":{"id":"sRshu-kM6vgh"},"source":["Here we will use `keras-tuner` to find the combination of hyperparameters that give us the best validation accuracy. The model will consist of a number of convolutional layers with a number of units, each followed by a max pooling layer. The `optimizer` will also be chosen by the tuner.\n","\n","I will also include methods such as Batch Normalization, Data Augmentation and Dropout in the hopes of creating a more robust, and generalized model. I have also included these methods to try combat the problem of overfitting obtained in the first `simple_model`.\n","\n","In testing the hyperparameter values I landed on choosing 6 convolutional layers. I will also decrease the number of filters along the layers."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bf1hjuuuSQ39"},"outputs":[],"source":["def build_model(hp):\n","    # random weight initialization\n","    hp_initialization = hp.Choice(\"initialization\", [\"random_normal\", \"glorot_uniform\"])\n","    # whether to batch normalize the layers\n","    hp_is_batch_normalized = hp.Boolean(\"is_batch_normalized\")\n","    # whether to perform dropout\n","    hp_do_dropout = hp.Boolean(\"do_dropout\")\n","    # whether to augment the data\n","    hp_data_augmentation = hp.Boolean(\"data_augmentation\")\n","    inputs = Input(shape=(224, 224, 3))\n","    if hp_data_augmentation:\n","      x = RandomFlip()(inputs)\n","      x = RandomRotation(factor=0.1)(x)\n","      x = RandomZoom(height_factor=0.1, width_factor=0.1)(x)\n","      x = RandomTranslation(height_factor=0.1, width_factor=0.1)(x)\n","    x = Rescaling(scale=1./255)(inputs)\n","    filters_per_layer = [128, 128, 64, 64, 32, 32]\n","    for i in range(6):\n","      x = Conv2D(filters=filters_per_layer[i], kernel_size=(3), activation=\"relu\", kernel_initializer=hp_initialization)(x)\n","      if hp_is_batch_normalized:\n","        x = BatchNormalization()(x)\n","      x = MaxPooling2D(pool_size=(2))(x)\n","      if hp_do_dropout:\n","        x = Dropout(rate=0.3)(x)\n","    x = Flatten()(x)\n","    outputs = Dense(units=1, activation=\"sigmoid\",\n","                    kernel_initializer=hp_initialization)(x)\n","    convnet = Model(inputs, outputs)\n","    # arrived to the conclusion of choosing 0.0001 as the learning rate, as other rates caused a worse performing model\n","    convnet.compile(optimizer=RMSprop(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n","    return convnet"]},{"cell_type":"markdown","metadata":{"id":"_cH2LdHe7ERi"},"source":["We will perform a random search on the hyperparameters, as to not have to try every single permutation of hyperparameters."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UXsMhrYyUwGJ"},"outputs":[],"source":["tuner = keras_tuner.RandomSearch(\n","    build_model,\n","    objective=\"val_accuracy\",\n","    directory=base_dir,\n","    project_name=\"ca2_tuner_state\",\n","    overwrite=True\n",")"]},{"cell_type":"markdown","metadata":{"id":"jyipJhpM7LC8"},"source":["Here we search the values of hyperparameters, setting the epochs to 10 as this seems to be a reasonable number that won't take an extremely long time to run."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"niVVqnh32aLL"},"outputs":[],"source":["tuner.search(\n","    train_dataset,\n","    epochs=10,\n","    validation_data=val_dataset\n",")"]},{"cell_type":"markdown","metadata":{"id":"WwEm3eB_7SP8"},"source":["We can see that the best validation accuracy obtained using the tuner was around 80%, which is pretty good. Let's see which combination of hyperparameters gave us this result."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XiLcTVcweCGE"},"outputs":[],"source":["tuner.get_best_hyperparameters()[0].values"]},{"cell_type":"markdown","metadata":{"id":"SzH3vFjV7d05"},"source":["We can see that the model didn't prefer to have many of Batch Normalization, Dropout, or Data Augmentation. I belive that this is because it would receive a higher validation accuracy without these methods of reducing the overfitting, but overall these make the model more robust. With running this model multiple times, `data_augmentation` seemed to be preferred most of the time. These methods help make the model learn the features of the images rather than potentially relying on 'memorizing' the training set or relying on shortcuts. On each run the hyperparameters varied slightly, but on most searches, the model preferred to not use most of these methods. The choice of `random_normal` and `glorot_uniform` also varied between the searches. I could create another model that is 'forced' to use each of the generalization techniques, but as I am implementing transfer learning later on, and this is expected to perform better, I will not include this extra model to save runtime on the notebook.\n","\n","Let's save the best model to perform some analysis."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HhnLNz-_6tb9"},"outputs":[],"source":["best_conv_model = tuner.get_best_models()[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7jryRezF8I6q"},"outputs":[],"source":["best_conv_model.summary()"]},{"cell_type":"markdown","metadata":{"id":"tuSbrJTI8t12"},"source":["\n","We can see that this model has around 290,000 parameters which is significantly lower than the number of parameters from the 'non convolutional layer' approach. This is because the convolutional layers 'slide' over the image reducing the dimension of the tensor, compared to essentially having every neuron look at every pixel of the image as shown in the `simple_model`. Let's fit this model on the training data, and plot it's history to see the trend of the loss and accuracy."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5d9QVsy49FxU"},"outputs":[],"source":["conv_model_history = best_conv_model.fit(train_dataset, epochs=30, validation_data=val_dataset, callbacks=[EarlyStopping(monitor=\"val_loss\", patience=4, restore_best_weights=True)], verbose=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DXLGbW0l9Lj2"},"outputs":[],"source":["train_acc, val_acc = conv_model_history.history[\"accuracy\"][-1], conv_model_history.history[\"val_accuracy\"][-1]\n","train_acc, val_acc"]},{"cell_type":"markdown","metadata":{"id":"-r4kwk-y9yWr"},"source":["This model has a training accuracy of around 87.5% and a fluctuating validation accuracy shows us that the model is definitely overfitting. Since our dataset is so small the model is not able to actually learn the generalized features of our classes, and has probably learned a shortcut to correctly identify the images in the training set.\n","\n","Even though the inclusion of Batch Normalization, Data Augmentation, and Dropout cause the training and validation errors to be less, they help the model overfit less and potentially allow the model to learn the features of our images. They lead to the creation of a more robust model.\n","\n","Lets plot the trend of the train and valiation loss along with the train and validation accuracy."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SWcozibO-Tav"},"outputs":[],"source":["plot_keras_history(conv_model_history, \"accuracy\")"]},{"cell_type":"markdown","metadata":{"id":"taS4KePJ_Ffj"},"source":["We can see that the loss and accuracy are both fluctuating quite a bit. Since our dataset is quite small, the model is sensitive to overfitting and the model is also sensitive to the shuffle of the data. I won't create a model that is forced to use all of Batch Normalization, Data Augmentation, and Dropout, since even though it will make the model 'better' in the sense that it will be less overfitting, it will also make the model 'worse' in terms of decreasing the accuracy since our dataset is so small.\n","\n","We can say that this model is still underfitting since we want to have the accuracy as close to 100% and the loss as close to 0 as we can. This may be the best we can do for the moment before introducing transfer learning. We will explore in `ca2_demo.ipynb` with some new example images, to test if our best model has learned any shortcuts, and what the model actually 'sees' when classifying the images. (i.e. what neurons activate in reponse to 'seeing' particular features in the image)\n","\n","Since our dataset is so small, it is hard to make a robust model that is actually learning the features of the images. This is where the idea of transfer learning comes in as we can use a model pre-trained on images already, and use the weights and biases it has learned. This allows us to create a more accurate model even with our smaller dataset of images."]},{"cell_type":"markdown","metadata":{"id":"ceH2Q51dedNo"},"source":["However, before we finish, let's see how this model does on the test set."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5DDNz03kezIu"},"outputs":[],"source":["test_results = best_conv_model.evaluate(test_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_lKVRqKMfQXm"},"outputs":[],"source":["print(f\"Accuracy on the test set: {test_results[1]}\")"]},{"cell_type":"markdown","metadata":{"id":"mHXUFnuofTZT"},"source":["This model had a 90% accuracy on the test set! Again, considering the size of the dataset we had for training, this is quite good although not the desired 100% accurate.\n","\n","Let's also visually inspect each predicted label along with the image."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"em9gXIYFLzZG"},"outputs":[],"source":["predictions = best_conv_model.predict(test_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PvFRq1SbMbr6"},"outputs":[],"source":["# taking a single batch of the test set as the plot_image_grid function was using the prediction titles from another batch of images\n","image_batch, label_batch = next(iter(test_dataset))\n","# predictions for this specific batch\n","batch_predictions = best_conv_model.predict(image_batch)\n","titles = np.where(batch_predictions > 0.5, \"car\", \"boat\")\n","# plotting the images\n","plt.figure(figsize=(10, 10))\n","for i in range(12):\n","    ax = plt.subplot(4, 3, i + 1)\n","    plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n","    plt.title(titles[i][0])\n","    plt.axis(\"off\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ahbJd0NgJMIb"},"source":["## Transfer Learning"]},{"cell_type":"markdown","metadata":{"id":"c-19hnl2gYM0"},"source":["Considering the small size of our image dataset, transfer learning could give us the best shot at having the most accurate model. I will use the `resnet50` model, which has already been pre-trained on over 1.4 million images in the ImageNet dataset.\n","\n","Since we are only interested in if the picture is one of a car or a boat, we will take the base fo the `resnet50` model, with all it's learned weights and biases, and then train it on our limited set of images by replacing the last layers."]},{"cell_type":"markdown","metadata":{"id":"RQkfn9NAh-sg"},"source":["First we take the base layers of the `resnet50` model, ignoring the top layer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iBfPKIc2hVbZ"},"outputs":[],"source":["resnet50_base = ResNet50(include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3))"]},{"cell_type":"markdown","metadata":{"id":"lT45mHWDh7--"},"source":["Creating the transfer learning model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BOV8K7eKh4WZ"},"outputs":[],"source":["inputs = Input(shape=(224, 224, 3))\n","x = resnet.preprocess_input(inputs)\n","x = resnet50_base(x)\n","x = Flatten()(x)\n","x = Dense(units=16, activation=\"relu\")(x)\n","outputs = Dense(units=1, activation=\"sigmoid\")(x)\n","transfer_model = Model(inputs=inputs, outputs=outputs)"]},{"cell_type":"markdown","metadata":{"id":"5KpFsA5-idon"},"source":["Freezing the weights in the layers of the `resnet50` base as to not overwrite the features that the model had learned previously."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hlBHvnqoiXFW"},"outputs":[],"source":["for layer in resnet50_base.layers:\n","  layer.trainable = False"]},{"cell_type":"markdown","metadata":{"id":"35zHqbNqiqKl"},"source":["Now to compile and train the model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"esl9gn74ioxa"},"outputs":[],"source":["transfer_model.compile(optimizer=(RMSprop(learning_rate=0.0001)), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KokWvf8Ci7LN"},"outputs":[],"source":["transfer_model_history = transfer_model.fit(train_dataset, epochs=10, validation_data=val_dataset, callbacks=[EarlyStopping(monitor=\"val_loss\", patience=4, restore_best_weights=True)], verbose=0)"]},{"cell_type":"markdown","metadata":{"id":"16K4y7fFjfkV"},"source":["To now look at the training and validation accuracies."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FG8XyHlYjH8h"},"outputs":[],"source":["train_acc, val_acc = transfer_model_history.history[\"accuracy\"][-1], transfer_model_history.history[\"val_accuracy\"][-1]\n","train_acc, val_acc"]},{"cell_type":"markdown","metadata":{"id":"8sVxoZWcjqlY"},"source":["This is the ideal model, with a training accuracy of 1 and a validation accuracy of 1, it seems that this model is perfect at classifying if an image is one of a car or a boat. This is because the `resnet50` model has already been trained on the ImageNet dataset, which contains different types of cars, and different types of boats, and the learned weights are able to be used in this way.\n","\n","Lets plot the loss and the accuracy of both the training and validation to see the overall trend as they increase or decrease."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d87wkkZlj8eT"},"outputs":[],"source":["plot_keras_history(transfer_model_history, \"accuracy\")"]},{"cell_type":"markdown","metadata":{"id":"G0YRabeKnxQZ"},"source":["It's clear from the graphs above that the transfer learning model didn't require much training in order to specialise the classes it already knew. Even by the end of the first epoch the loss was near-zero, and the accuracy was 1.0. This shows the power of transfer learning. I am not going to unfreeze the non-Batch Normalization layers as, our dataset is quite small and I don't want the model to begin overfitting on our training set. Also inside this training set, there are not many diverse or 'edge-cases' to check.\n","\n","(I did try unfreezing these layers, and it made the model perform worse on the example images in `ca2_demo.ipynb`)"]},{"cell_type":"markdown","metadata":{"id":"OyTUZ_qGoKqb"},"source":["Let's view how this model does on the test set."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WPsUKVSMoZz_"},"outputs":[],"source":["transfer_model_history = transfer_model.evaluate(test_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cuYRYhC_ojKo"},"outputs":[],"source":["test_results = transfer_model.evaluate(test_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w6BoUwAEoz0Y"},"outputs":[],"source":["print(f\"Accuracy on the test set {test_results[1]}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m6fnrU0ioKFs"},"outputs":[],"source":["predictions = transfer_model.predict(test_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MjTgOjNxoQFl"},"outputs":[],"source":["image_batch, label_batch = next(iter(test_dataset))\n","batch_predictions = transfer_model.predict(image_batch)\n","titles = np.where(batch_predictions > 0.5, \"car\", \"boat\")\n","plt.figure(figsize=(10, 10))\n","for i in range(12):\n","    ax = plt.subplot(4, 3, i + 1)\n","    plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n","    plt.title(titles[i][0])\n","    plt.axis(\"off\")\n","plt.show()"]},{"cell_type":"markdown","source":["After completing the transfer learning, it's clear that it's the best model. It seems to be able to perfectly classify the images and tell us whether they are an image of a boat or a car. We can now save this model to the file to explore it's learnings in `ca2_demo.ipynb`."],"metadata":{"id":"Ln5RFu9-6q_8"}},{"cell_type":"code","source":["transfer_model.save(os.path.join(base_dir, \"transfer_model.keras\"))"],"metadata":{"id":"_-d7R57265JL"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyOOjFAk3pUY1xp0IgggbgRb"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}